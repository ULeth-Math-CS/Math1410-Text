%In the last chapter we studied vectors from a geometric point of view. In this chapter we make the transition to algebra. (This is, after all, an algebra textbook.) We will see shortly that vectors are a special case of more general objects called \sword{matrices}.

In the last chapter we learned how to solve systems of equations, and along the way, we saw that a key tool for solving systems efficiently was the use of \sword{matrices}. In this chapter, we will finally give a proper definition of what, exactly, a matrix is, after which we will proceed to develop the algebraic properties of matrices, just as we did for vectors in Chapter \ref{chapter:vectors}.

A fundamental topic of mathematics is arithmetic; adding, subtracting, multiplying and dividing numbers. After learning how to do this, most of us went on to learn how to add, subtract, multiply and divide ``$x$''. We are comfortable with expressions such as 
\[
x+3x-x\cdot x^2+x^5\cdot x^{-1}
\]
and know that we can ``simplify'' this to 
\[
4x-x^3+x^4.
\]

This chapter deals with the idea of doing similar operations, but instead of an unknown number $x$, we will be using a matrix \tta. So what exactly does the expression 
\[
\tta+3\tta-\tta\cdot \tta^2+\tta^5\cdot \tta^{-1}
\]
mean? Before we can do anything, we need to actually define what a matrix is! Once we've taken care of that, we are going to need to learn to define what matrix addition, scalar multiplication, matrix multiplication and matrix inversion are. We will learn just that, plus some more good stuff, in this chapter.

\section{Matrix Addition and Scalar Multiplication}\label{sec:matrix_arithmetic_1}

\asyouread{
\item What is remarkable about the definition of a matrix?
\item When are two matrices equal?
\item Write an explanation of how to add matrices as though writing to someone who knows what a matrix is but not much more.
\item T/F: There is only 1 zero matrix.
\item T/F: To multiply a matrix by 2 means to multiply each entry in the matrix by 2.
}

As mentioned above, a \sword{matrix} is a construction that allows us to organize information in a tabular form. For example, we may be interested in the following (made up) data involving crop yields on several Southern Alberta farms, given in tabular form:

\noindent\begin{minipage}{\textwidth}
\begin{center}
\begin{tabular}{l|cccc|}
	 & Corn & Potatoes & Soybeans & Wheat\\
\hline 
 Farm A & 48 & 18 & 92 & 0\\
 Farm B & 0 & 0 & 73 & 152\\
 Farm C & 34 & 203 & 0 & 88\\
 \hline
\end{tabular}
\end{center}
\captionsetup{type=figure}
\caption{2014 crop yields, in metric tonnes}
\end{minipage}

\medskip

Someone in charge of compiling data on farms and crops probably already has a program or spreadsheet set up with all of the farms and crops pre-defined; what they are interested in are the numbers giving the crop yields. Thus, when they enter their data into the computer, they are probably more interested in the array
\begin{equation}\label{eq:farmmatrix}
A = \bbm 48 & 18 & 92 & 0\\ 0 & 0 & 73 & 152\\ 34 & 203 & 0 & 88 \ebm.
\end{equation}
As long as we're consistent and always assign each farm to the same row, and each crop to the same column, we can dispense with the labels and work directly with the data.

\mnote{.4}{Matrices work well in situations such as our farming example where the data we need to organize falls into two categories, in this case, farms and crops. What if our data depends on three or more categories? (Perhaps we also want to track type of fertilizer?) It turns out that along with matrices, mathematicians have invented higher-dimensional arrays called tensors, that can handle almost any data organization scenario you can think of. Tensors are usually encountered in more advanced courses in abstract algebra.}

The array above is our first example of a matrix, which we now define.
The definition of matrix is remarkable only in how unremarkable it seems -- it is simply a way of organizing information (usually numbers) into an array.

%\enlargethispage{2\baselineskip}
\smallskip

\definition{def:matrix}{Matrix}{
\index{matrix!definition}
A {\em matrix} is a rectangular array of numbers.\\

The horizontal lines of numbers form {\em rows} and the vertical lines of numbers form {\em columns}. A matrix with $m$ rows and $n$ columns is said to be an $m\times n$ matrix (``an $m$ by $n$ matrix'', or a matrix of \sword{size} $m\times n$). \\

The entries of an $m\times n$ matrix are indexed as follows:
\[
\bmx{ccccc}
a_{11}&a_{12}&a_{13}&\cdots&a_{1n}\\
a_{21}&a_{22}&a_{23}&\cdots&a_{2n}\\
a_{31}&a_{32}&a_{33}&\cdots&a_{3n}\\
\vdots&\vdots&\vdots&\ddots&\vdots\\
a_{m1}&a_{m2}&a_{m3}&\cdots&a_{mn} \emx.
\]

That is, $a_{32}$ means ``the number in the third row and second column.'' To save space, we will sometimes use the shorthand notation $A = [a_{ij}]$ to denote a matrix $A$ with entries $a_{ij}$. If we need to specify the size, we can also write $A=[a_{ij}]_{m\times n}$.}

\smallskip

Two special types of matrix are worth noting: those with a single row or column. Such matrices are known as \sword{vectors}.

\smallskip

\definition{def:rcvect}{Row and column vectors}{
\index{row vector}\index{column vector}\index{vector ! row} \index{vector ! column}
A \sword{row vector} is a $1\times n$ matrix of the form
\[
R = \bbm r_1 & r_2 & \cdots & r_n\ebm.
\]
A \sword{column vector} is a $m\times 1$ matrix of the form
\[
C = \bbm c_1\\c_2\\ \vdots \\ c_m\ebm.
\]
}

\smallskip

In particular, we can obtain row or column vectors by isolating any row or column of a given $m\times n$ matrix. For example, given our matrix of crop data in Equation \eqref{eq:farmmatrix}, we might be interested only in Farm B, in which case we would want the row vector
\[
R_B = \bbm 0 & 0 & 73 & 152\ebm.
\]
Similarly, we might only be interested in yields for soybean crops, in which case the column vector
\[
C_{\text{soy}} = \bbm 92 \\ 73\\0\ebm
\]
is our object of interest.


Continuing with our farming example, suppose that in addition to the matrix $A$ of 2014 crop yields above we also have data for 2015 crop yields given by
\[
B = \bbm 41 & 25 & 15 & 20\\ 0 & 72 & 0 & 165\\ 47 & 193 & 0 & 77\ebm.
\]
We might be interested in quantities such as the total crop yields over two years. If we arrange these totals into a matrix $T$, it seems like it should be reasonable to define matrix addition in such a way that we can write
\[
T = A + B.
\]
This leads to two questions. First, how do we define matrix addition in order to ensure this outcome? Second, and perhaps more fundamentally, what do we mean by ``$=$'' in the context of matrices? Let us tackle the second question first.

\smallskip

\definition{def:matrix_equality}{Matrix Equality}{
\index{matrix!equality} Two $m\times n$ matrices \tta\ and \ttb\ are \sword{equal} if their corresponding entries are equal.} 

\smallskip

Notice that our more formal definition specifies that if matrices are equal, they have the same size. This should make sense.

Now we move on to describing how to add two matrices together. To start off, take a wild stab: how do you think we should add our matrices of crop data above? Well, if we want the sum to represent the total yields for each crop, then it stands to reason that to add the two matrices, we add together each of the corresponding crop yields within them:

\begin{align*}
T & = A+B\\
  & = \bbm 48 & 18 & 92 & 0\\ 0 & 0 & 73 & 152\\ 34 & 203 & 0 & 88 \ebm + \bbm 41 & 25 & 15 & 20\\ 0 & 72 & 0 & 165\\ 47 & 193 & 0 & 77\ebm\\
  & = \bbm 48+41 & 18+25 & 92+15 & 0+20\\ 0 + 0 & 0 + 72 & 73 + 0 & 152 +165\\ 34+47 & 203 + 193 & 0 + 0 & 88+77\ebm\\
  & = \bbm 89 & 43 & 107 & 20\\0& 72 & 73 & 317\\81 & 396 & 0 & 165\ebm.
\end{align*}

So to add the two matrices, we added their corresponding entries. This is exactly how we define matrix addition in general:

\smallskip

\definition{def:addition}{Matrix Addition}{\index{matrix!addition}
Let $A=[a_{ij}]$ and $B=[b_{ij}]$ be $m\times n$ matrices. The \sword{sum} of \tta\ and \ttb, denoted $\tta+\ttb$, is 
\[
\bmx{cccc} a_{11}+b_{11}&a_{12}+b_{12}&\cdots&a_{1n}+b_{1n}\\ a_{21}+b_{21}&a_{22}+b_{22}&\cdots&a_{2n}+b_{2n}\\\vdots&\vdots&\ddots&\vdots\\ a_{m1}+b_{m1}&a_{m2}+b_{m2}&\cdots&a_{mn}+b_{mn}\emx.
\]}

\smallskip

For another example, suppose we wanted to know the total production for each farm in 2014, assuming that our matrices represent all of the crops each farm produces. This would be obtained by simply calculating the total for each row in the matrix $A$. Another way to accomplish the same task is as follows: let
\[
C_1 = \bbm 48\\0\\34\ebm, C_2 = \bbm 18\\0\\203\ebm, C_3 = \bbm 92\\73\\0\ebm, C_4 = \bbm 0\\152\\88\ebm
\]
denote the columns of the matrix $A$; note that each column represents the yields across all three farms for each crop. The total yield for each farm can then be calculated according to
\begin{align*}
Y & = C_1+C_2+C_3+C_4\\
 & \bbm 48\\0\\34\ebm + \bbm 18\\0\\203\ebm + \bbm 92\\73\\0\ebm + \bbm 0\\152\\88\ebm = \bbm 158\\225\\325\ebm.
\end{align*}
The column vector $Y$ then contains the total yields for each farm. Notice that although we only defined the sum of \textit{two} matrices in Definition \ref{def:addition}, it makes sense to add any number of matrices, and there is no need to add parentheses.

Recall from Chapter \ref{chapter:vectors} that we defined the multiplication of a vector $\vec{v} = \langle a, b, c\rangle$ by a scalar $t\in\mathbb{R}$ by
\[
t\vec{v} = t\langle a, b, c\rangle = \langle ta, tb, tc\rangle.
\]

%\mnote{.25}{\textbf{Note:}
%From this point onwards, we dispense with the angle bracket notation for vectors in favour of row and column vectors. For the remainder of the book, when we use the term ``vector'', we will almost always be referring to a column vector.
%We'll see in Sections \ref{sec:matrix_multiplication} and \ref{sec:geom_3} that writing vectors as column vectors allows us to define \textit{transformations} of vectors in terms of matrix multiplication.}

It stands to reason that scalar multiplication should be defined in exactly the same way for row and column vectors; after all, in most cases these are just different ways of writing down the same mathematical object. Thus, in order to multiply a row or column vector by a scalar, we should multiply each entry in the vector by that scalar. From here, it's not too much of a stretch to conclude that the same definition is reasonable for matrices in general.


\definition{def:scalar_multiplication}{Scalar Multiplication}{\index{matrix!scalar multiplication}
Let $\tta = [a_{ij}]$ be an $m\times n$ matrix and let $k$ be a scalar. The \sword{scalar multiplication} \tta\ by $k$, denoted $k\tta$, is defined by
\[
\bmx{cccc}ka_{11}&ka_{12}&\cdots&ka_{1n}\\ka_{21}&ka_{22}&\cdots&ka_{2n}\\\vdots&\vdots&\ddots&\vdots\\ka_{m1}&ka_{m2}&\cdots&ka_{mn}\emx.
\]}

\smallskip

\mnote{.75}{\textbf{Note:} In Linear Algebra, a \sword{scalar}\index{scalar} is simply a number. For most of this text, the scalars we consider are real numbers, although one can also use complex numbers as scalars. (Complex numbers will be introduced in Chapter \ref{chapter:complex}.)  As we saw in Chapter \ref{chapter:vectors}, multiplying a vector by a scalar \textit{scales} the length of that vector.}

Referring one last time to our farming data, we could imagine that a fertilizer company is advertising a new product they claim will increase crop yields by 30\%. Increasing the yield of each crop by 30\% amounts to multiplying each of the entries in the matrices $A$ or $B$ by a factor of 1.3; according to Definition \ref{def:scalar_multiplication}, this is the same as forming the scalar multiples $1.3\tta$ and $1.3\ttb$.

Since we have two years' worth of crop data, we could also ask for the \textit{average} yield for each crop on each farm. For example, Farm A produced 48 tonnes of corn in 2014, and 41 tonnes of corn in 2015. The two-year average for corn on Farm A is thus
\[
\frac{48+41}{2} = \frac{89}{2} = 44.5 \text{ tonnes}.
\]
Notice that we can obtain the average for each entry by dividing each entry in $T=A+B$ by 2, which is the same thing as multiplying by $\frac{1}{2}$. Our matrix of averages is
\[
\frac{1}{2}T = \frac{1}{2}\bbm 89 & 43 & 107 & 20\\0& 72 & 73 & 317\\81 & 396 & 0 & 165\ebm = \bbm 89/2 & 43/2 & 107/2 & 10\\0& 36 & 73/2 & 317/2\\81/2 & 198 & 0 & 165/2\ebm.
\]
Finally, notice also that since
\[
\frac{48+41}{2} = \frac{1}{2}(48)+\frac{1}{2}(41),
\]
with similar considerations for the other entries, we also could have obtained the average by first dividing $A$ and $B$ by $\frac{1}{2}$, and then adding the result. That is,
\[
\frac{1}{2}T = \frac{1}{2}(A+B) = \frac{1}{2}A +\frac{1}{2}B.
\]
We'll see shortly that this result is due to a general property of matrix arithmetic, called the \textit{distributive property}.

Expressions such as $\frac12 A+\frac12 B$ that use both addition and scalar multiplication together occur frequently in Linear Algebra, and are known as \sword{linear combinations}. In general, a linear combination can be formed from any number of matrices, as long as they're all of the same size.

\smallskip

\definition{def:linear_combination}{Linear combination}{
\index{linear combination}
Given $m\times n$ matrices $A_1, A_2, \ldots, A_k$, a \sword{linear combination} of these matrices is any expression of the form
\[
B = c_1A_1+c_2A_2+\cdots +c_kA_k,
\]
where $c_1, c_2, \ldots, c_k$ are scalars.}

\smallskip

It is time to forget our farm data and move into some abstract computational examples to make sure we have the hang of these new operations.

\medskip

\example{ex_mat_add_1}{Matrix addition and scalar multiplication}{ Let 
\[
\tta = \bmx{ccc}1&2&3\\-1&2&1\\5&5&5\emx,\quad \ttb = \bmx{ccc}2&4&6\\1&2&2\\-1&0&4\emx,\quad \ttc = \bmx{ccc} 1&2&3\\9&8&7\emx.
\]
Simplify the following matrix expressions.
\begin{multicols}{3}
\begin{enumerate}
	\item	$\tta+\ttb$
	\item	$\ttb+\tta$
	\item	$\tta-\ttb$
	\item	$\tta + \ttc$
	\item	$-3\tta +2\ttb$
	\item	$\tta -\tta$
	\item	$5\tta + 5\ttb$
	\item	$5(\tta+\ttb)$
\end{enumerate}
\end{multicols}}
{\begin{enumerate}
	\item	Adding the corresponding entries of $A$ and $B$, we have
	\[
	\tta + \ttb =
	\bmx{ccc}1+2&2+4&3+6\\-1+1&2+2&1+2\\5-1&5+0&5+4\emx = \bmx{ccc}3&6&9\\0&4&3\\4&5&9\emx.
	\]
	\item	To compute $B+A$, we again add the corresponding entries, but in the opposite order:
	\[
	\ttb + \tta = \bmx{ccc}2+14+2&6+3\\1-1&2+2&2+1\\-1+5&0+5&4+5\emx = \bmx{ccc}3&6&9\\0&4&3\\4&5&9\emx.
	\]
	\item  In this case, we have to subtract the entries of $B$ from those of $A$. This gives us
	\[
	\tta - \ttb = \bmx{ccc}-1&-2&-3\\-2&0&-1\\6&5&1\emx.
	\]
	\item		$\tta + \ttc$ is not defined. If we look at our definition of matrix addition, we see that the two matrices need to be the same size. Since \tta\ and \ttc\ have different dimensions, we don't even try to create something as an addition; we simply say that the sum is not defined.
	\item	To compute this linear combination we first carry out the scalar multiplication, followed by the addition:
	\begin{align*}
	-3\tta + 2\ttb & = -3\bmx{ccc}1&2&3\\-1&2&1\\5&5&5\emx + 2\bmx{ccc}2&4&6\\1&2&2\\-1&0&4\emx\\
	& = \bmx{ccc}-3&-6&-9\\3&-6&-3\\-15&-15&-15\emx + \bmx{ccc}4&8&12\\2&4&4\\-2&0&8\emx\\
	&= \bmx{ccc}1&2&3\\5&-2&1\\-17&-15&-7\emx.
	\end{align*}
	\item	Subtracting each entry of $A$ from itself, we get 
	\[
	\tta - \tta = \bmx{ccc}0&0&0\\0&0&0\\0&0&0\emx.
	\]
	\item	Carrying out the scalar multiplication followed by the addition, we find
	\[
	5A+5B = \bmx{ccc}5&10&15\\-5&10&5\\25&25&25\emx +\bmx{ccc}10&20&30\\5&10&10\\-5&0&20\emx = \bmx{ccc}15&30&45\\0&20&15\\20&25&45\emx.
	\]
	\item	In this case, we first perform the addition, followed by the scalar multiplication. We obtain:
\begin{align*}
5\left(\bmx{ccc}1&2&3\\-1&2&1\\5&5&5\emx + \bmx{ccc}2&4&6\\1&2&2\\-1&0&4\emx\right) &= 5\cdot\bmx{ccc}3&6&9\\0&4&3\\4&5&9\emx  \\
                   &= \bmx{ccc}15&30&45\\0&20&15\\20&25&45\emx.
\end{align*}
\end{enumerate}
\vskip -\baselineskip}

\medskip


Our example raised a few interesting points. Notice how $\tta + \ttb = \ttb + \tta$. We probably aren't surprised by this, since we know that when dealing with numbers, $a+b = b+a$. Also, notice that $5\tta+5\ttb = 5(\tta+\ttb)$. In our example, we were careful to compute each of these expressions following the proper order of operations; knowing these are equal allows us to compute similar expressions in the most convenient way. 

Another interesting thing that came from our previous example is that 
\[
\tta - \tta = \bmx{ccc}0&0&0\\0&0&0\\0&0&0\emx.
\]
It seems like this should be a special matrix; after all, every entry is 0 and 0 is a special number. 

In fact, this is a special matrix. We define \tto, which we read as ``the zero matrix,'' to be the matrix of all zeros. We should be careful; this previous ``definition'' is a bit ambiguous, for we have not stated what size the zero matrix should be. Is $\bmx{cc}0&0\\0&0\\ \emx$ the zero matrix? How about $\bmx{cc} 0&0\emx$?

Let's not get bogged down in semantics. If we ever see \tto\ in an expression, we will usually know right away what size \tto\ should be; it will be the size that allows the expression to make sense. If \tta\ is a $3\times 5$ matrix, and we write $\tta + \tto$, we'll simply assume that \tto\ is also a $3\times 5$ matrix. If we are ever in doubt, we can add a subscript; for instance, $\tto_{2\times 7}$ is the $2\times7$ matrix of all zeros.

Since the zero matrix is an important concept, we give it its own definition box.

\smallskip

\definition{def:zero_matrix}{The Zero Matrix}{
\index{zero matrix}\index{matrix!the zero matrix}The $m\times n$ matrix of all zeros, denoted $\tto_{m\times n}$, is the \sword{zero matrix}.\\

When the dimensions of the zero matrix are clear from the context, the subscript is generally omitted.}

\smallskip

\mnote{.8}{We use the bold face to distinguish the zero matrix, \tto, from the number zero, 0. }

%\enlargethispage{3\baselineskip}

The following presents some of the properties of matrix addition and scalar multiplication that we discovered above, plus a few more.

\smallskip

\theorem{thm:addition_properties}{Properties of Matrix Addition and Scalar Multiplication}{\index{matrix!arithmetic properties}
The following equalities hold for all $m\times n$ matrices \tta, \ttb\ and \ttc\ and scalars $k$.
\begin{enumerate}
	\item	$\tta+\ttb = \ttb + \tta$ (Commutative Property)
	\item	$(\tta+\ttb)+\ttc = \tta + (\ttb+\ttc)$ (Associative Property)
	\item	$k(\tta + \ttb) = k\tta + k\ttb$ (Scalar Multiplication Distributive Property)
	\item	$k\tta = \tta k$
	\item	$\tta +\tto = \tto+\tta = \tta$ (Additive Identity)
	\item	$0\tta = \tto$
	\end{enumerate}
}

\smallskip

Be sure that this last property makes sense; it says that if we multiply any matrix by the \textit{number} 0, the result is the \textit{zero matrix}, or \tto. (You now have more than one kind of zero to keep track of!)

It's important to understand that since matrix addition and scalar multiplication are defined in terms of the entries of our matrices, the properties in Theorem \ref{thm:addition_properties} follow directly from the properties of real number arithmetic in Section \ref{RealNumberArithmetic}. For example to prove item 1 above, let $A=[a_{ij}]$ and $B=[b_{ij}]$ be $m\times n$ matrices. We then have
\begin{align*}
A+B & = [a_{ij}]+[b_{ij}]\\
& = [a_{ij}+b_{ij}] \tag*{by Definition \ref{def:addition}}\\
& = [b_{ij}+a_{ij}] \tag*{since addition of real numbers commutes}\\
& = [b_{ij}]+[a_{ij}] \tag*{by Definition \ref{def:addition}}\\
& = B+A.
\end{align*}
Similarly, the distributive property in item 3 is valid since
\begin{align*}
k(A+B) & = k([a_{ij}]+[b_{ij}])\\
 & = k[a_{ij}+b_{ij}] \tag*{definition of matrix addition}\\
 & = [k(a_{ij}+b_{ij})] \tag*{definition of scalar multiplication}\\
 & = [k\cdot a_{ij}+k\cdot b_{ij}] \tag*{distributive property of real numbers}\\
 & = [k\cdot a_{ij}] + [\cdot b_{ij}] \tag*{definition of matrix addition}\\
 & = k[a_{ij}]+k[b_{ij}] \tag*{definition of scalar multiplication}\\
 & = kA +kB.
 \end{align*}
The verification of the remaining properties in Theorem \ref{thm:addition_properties} is similar, and left as an exercise for the reader.

We began this section with the concept of matrix equality. Let's put our matrix addition properties to use and solve a matrix equation.\\

%\pagebreak

\example{ex_equal}{Solving a matrix equation}{
Let 
\[
\tta = \bmx{cc} 2&-1\\3&6\emx.
\]
Find the matrix \ttx\ such that 

\[
2\tta + 3\ttx = -4\tta.
\]}
{We can use basic algebra techniques to manipulate this equation for \ttx; first, let's subtract $2\tta$ from both sides. This gives us 
\[
3\ttx = -6\tta.
\]
Now divide both sides by 3 to get 
\[
\ttx = -2\tta.
\]
Now we just need to compute $-2\tta$; we find that 
\[
\ttx = \bmx{cc} -4&2\\ -6&-12\emx.
\]
}

\medskip

Our matrix properties identified \tto\ as the Additive Identity; i.e., if you add \tto\ to any matrix \tta, you simply get \tta. This is similar in notion to the fact that for all numbers $a$, $a+0 = a$. A \textit{Multiplicative Identity} would be a matrix \tti\ where $\tti\times\tta = \tta$ for all matrices \tta. (What would such a matrix look like? A matrix of all 1s, perhaps?) However, in order for this to make sense, we'll need to learn to multiply matrices together, which we'll do in the next section. \\
%This probably gets us thinking; we know that $a\cdot 1 = a$ for all numbers $a$. Is there a similar thing for matrices? (A matrix of all 1's, perhaps?) Before we can answer this, we need to define what matrix multiplication is. You are likely to be surprised by what we find.\\

%In the next section we'll further our practice with adding matrices and multiplying them by scalars. However, we'll ``look'' at them in a different way -- that is, we'll actually visualize special matrices and see what it means to add them together and multiply them by numbers. Then, in the section after that, we'll learn what it means to multiply two matrices together. \\

%Exercises: simplify some simple expressions Include adding vectors  Solve matrix equation based on idea of matrix equality\\

%solve $c_1\vu + c_2\vv =\vw$

\printexercises{exercises/02_01_exercises}

